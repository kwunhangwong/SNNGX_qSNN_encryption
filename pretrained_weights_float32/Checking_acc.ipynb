{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOW device is using: cpu\n"
     ]
    }
   ],
   "source": [
    "import torch \n",
    "import torch.nn as nn           #  Feedforward and Loss function\n",
    "import torch.optim as optim     #  Gradient Descent\n",
    "import torch.nn.functional as F #  Functions that dont accept parameters \n",
    "from torch.utils.data import DataLoader  #  Data set Management i.e. creat mini-Batches\n",
    "\n",
    "from torch.autograd import Function\n",
    "import tonic\n",
    "import tonic.transforms as transforms\n",
    "\n",
    "\n",
    "# Hyperparameters\n",
    "in_channels = 2 \n",
    "num_classes = 11 \n",
    "learning_rate = 1e-5\n",
    "batch_size = 8\n",
    "########## SNN ###########\n",
    "T_BIN = 15\n",
    "VTH = 0.3       #0.3\n",
    "DECAY = 0.3     #0.3\n",
    "########## Surrogate ###########\n",
    "alpha = 0.5  #alpha = lens*2\n",
    "\n",
    "#Device\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"NOW device is using: {device}\")\n",
    "\n",
    "\n",
    "# Dataset - DVS-Gesture\n",
    "# 2 x 128 x 128\n",
    "sensor_size = tonic.datasets.DVSGesture.sensor_size\n",
    "frame_transform = transforms.Compose([transforms.Denoise(filter_time=10000),\n",
    "                                      transforms.ToFrame(sensor_size=sensor_size, n_time_bins=T_BIN)])\n",
    "    \n",
    "trainset = tonic.datasets.DVSGesture(save_to=\"../dataset/\",transform=frame_transform, train=True)\n",
    "testset = tonic.datasets.DVSGesture(save_to=\"../dataset/\", transform=frame_transform, train=False)\n",
    "\n",
    "#collation整理 => pad out填充 shorting recordings to have same dimension\n",
    "train_loader = DataLoader(\n",
    "    dataset = trainset,\n",
    "    batch_size= batch_size,\n",
    "    collate_fn= tonic.collation.PadTensors(batch_first=False),\n",
    "    shuffle = True,\n",
    "    drop_last=True\n",
    ")\n",
    "\n",
    "test_loader = DataLoader(\n",
    "    dataset = testset,\n",
    "    batch_size= batch_size,\n",
    "    collate_fn= tonic.collation.PadTensors(batch_first=False),\n",
    "    shuffle = False,\n",
    "    drop_last=True\n",
    ")\n",
    "\n",
    "\n",
    "class CSNN_Model(nn.Module):\n",
    "\n",
    "    def __init__(self,in_channels,num_classes):\n",
    "        super(CSNN_Model,self).__init__()\n",
    "\n",
    "        self.pool  = nn.MaxPool2d(2,2)\n",
    "\n",
    "        self.conv0 = nn.Conv2d(in_channels, 64, kernel_size=3, stride=1, padding=1, bias=False)  #128x128 \n",
    "        self.conv1 = nn.Conv2d( 64 , 128, kernel_size=3,  stride=1, padding=1, bias=False)        #64x64 \n",
    "        self.conv2 = nn.Conv2d( 128 , 128, kernel_size=3, stride=1, padding=1, bias=False)       #32x32\n",
    "        self.conv3 = nn.Conv2d( 128 , 256, kernel_size=3, stride=2, padding=1, bias=False)       #16x16\n",
    "\n",
    "        self.fc1   = nn.Linear(4 * 4 * 256, 1024, bias = False)  # 4096*1024 \n",
    "        self.fc2   = nn.Linear(1024, num_classes, bias = False) \n",
    "\n",
    "    def forward(self,input):\n",
    "\n",
    "        # Reseting Neurons\n",
    "        c0_mem = c0_spike = torch.zeros(batch_size, 64, 128, 128,  device=device)\n",
    "        c1_mem = c1_spike = torch.zeros(batch_size, 128, 64, 64, device=device) \n",
    "        c2_mem = c2_spike = torch.zeros(batch_size, 128, 32, 32, device=device)\n",
    "        c3_mem = c3_spike = torch.zeros(batch_size, 256, 8, 8, device=device)\n",
    "\n",
    "        h1_mem = h1_spike = torch.zeros(batch_size, 1024, device=device)\n",
    "        h2_mem = h2_spike = h2_sumspike = torch.zeros(batch_size, num_classes, device=device)\n",
    "\n",
    "        for i in range(T_BIN): # Every single piece of t belongs to T\n",
    "            # .view change shape/dtype of tensor #####  -1 squeeze all dimension to 1 \n",
    "            # #1 tensor(N,P,H,W,T) to vector, #2 vector to tensor(N,-1)\n",
    "            x = input[i,:,:,:,:].to(device)\n",
    "\n",
    "            c0_mem, c0_spike = mem_update(self.conv0, x, c0_mem, c0_spike)\n",
    "            p0_spike = self.pool(c0_spike)\n",
    "            \n",
    "            c1_mem, c1_spike = mem_update(self.conv1, p0_spike, c1_mem, c1_spike) \n",
    "            p1_spike = self.pool(c1_spike) \n",
    "\n",
    "            c2_mem, c2_spike = mem_update(self.conv2, p1_spike, c2_mem, c2_spike) \n",
    "            p2_spike = self.pool(c2_spike) \n",
    "\n",
    "            c3_mem, c3_spike = mem_update(self.conv3, p2_spike, c3_mem, c3_spike) \n",
    "            p3_spike = self.pool(c3_spike) \n",
    "\n",
    "            x = p3_spike.view(batch_size, -1)\n",
    "\n",
    "            h1_mem, h1_spike = mem_update(self.fc1, x, h1_mem, h1_spike)\n",
    "            h2_mem, h2_spike = mem_update(self.fc2, h1_spike, h2_mem, h2_spike)\n",
    "            h2_sumspike += h2_spike\n",
    "\n",
    "        # Where SumSpike = (N,#neurons) (2D matrix)/scalar \n",
    "        outputs = h2_sumspike / T_BIN\n",
    "        # print(torch.mean(outputs,dim=0))\n",
    "        return outputs\n",
    "\n",
    "\n",
    "class ActivationFun(torch.autograd.Function):\n",
    "# For forward: 1/0 spike\n",
    "# For backward: Surrogate gradient -> unit retangular functionv rect(t) = 1/a if -a/2 < t < +a/2\n",
    "# h1(t) in spatio-temporal backpropagation by (Wu etal., 2018) \n",
    "\n",
    "    @staticmethod\n",
    "    def forward(ctx, input):\n",
    "        ctx.save_for_backward(input)\n",
    "        return input.gt(VTH).float()      # torch.gt(a,b) compare a and b : return 1/0 spike\n",
    "\n",
    "    @staticmethod\n",
    "    def backward(ctx, grad_output):\n",
    "        input, = ctx.saved_tensors\n",
    "        grad_input = grad_output.clone()\n",
    "        temp = abs(input - VTH) < alpha/2    # lens = alpha/2\n",
    "        return grad_input * temp.float() / alpha  # intensify spiking output (Wu et. 2018 w/o 2*len) \n",
    "\n",
    "act_fun = ActivationFun.apply\n",
    "\n",
    "def mem_update(fc, x, volt, spike):\n",
    "    volt = volt * DECAY * (1 - spike) + fc(x)\n",
    "    spike = act_fun(volt)\n",
    "    return volt, spike\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Error(s) in loading state_dict for CSNN_Model:\n\tsize mismatch for fc2.weight: copying a param with shape torch.Size([10, 1024]) from checkpoint, the shape in current model is torch.Size([11, 1024]).",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[38], line 8\u001b[0m\n\u001b[1;32m      6\u001b[0m weight_path \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m./pretrained_normal_CIFAR_csnn_150_q.t7\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m      7\u001b[0m checkpoint \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mload(weight_path,map_location\u001b[39m=\u001b[39mdevice)\n\u001b[0;32m----> 8\u001b[0m model\u001b[39m.\u001b[39;49mload_state_dict(checkpoint[\u001b[39m'\u001b[39;49m\u001b[39mnet\u001b[39;49m\u001b[39m'\u001b[39;49m])\n\u001b[1;32m     10\u001b[0m \u001b[39m#Model evaluation\u001b[39;00m\n\u001b[1;32m     11\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mcheck_accuracy\u001b[39m(loader, model):\n",
      "File \u001b[0;32m~/anaconda3/envs/SNN_Research/lib/python3.9/site-packages/torch/nn/modules/module.py:1671\u001b[0m, in \u001b[0;36mModule.load_state_dict\u001b[0;34m(self, state_dict, strict)\u001b[0m\n\u001b[1;32m   1666\u001b[0m         error_msgs\u001b[39m.\u001b[39minsert(\n\u001b[1;32m   1667\u001b[0m             \u001b[39m0\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mMissing key(s) in state_dict: \u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m. \u001b[39m\u001b[39m'\u001b[39m\u001b[39m.\u001b[39mformat(\n\u001b[1;32m   1668\u001b[0m                 \u001b[39m'\u001b[39m\u001b[39m, \u001b[39m\u001b[39m'\u001b[39m\u001b[39m.\u001b[39mjoin(\u001b[39m'\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m\"\u001b[39m\u001b[39m'\u001b[39m\u001b[39m.\u001b[39mformat(k) \u001b[39mfor\u001b[39;00m k \u001b[39min\u001b[39;00m missing_keys)))\n\u001b[1;32m   1670\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(error_msgs) \u001b[39m>\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[0;32m-> 1671\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mRuntimeError\u001b[39;00m(\u001b[39m'\u001b[39m\u001b[39mError(s) in loading state_dict for \u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m:\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\\t\u001b[39;00m\u001b[39m{}\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m.\u001b[39mformat(\n\u001b[1;32m   1672\u001b[0m                        \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__class__\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\\t\u001b[39;00m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mjoin(error_msgs)))\n\u001b[1;32m   1673\u001b[0m \u001b[39mreturn\u001b[39;00m _IncompatibleKeys(missing_keys, unexpected_keys)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Error(s) in loading state_dict for CSNN_Model:\n\tsize mismatch for fc2.weight: copying a param with shape torch.Size([10, 1024]) from checkpoint, the shape in current model is torch.Size([11, 1024])."
     ]
    }
   ],
   "source": [
    "#Network initialization \n",
    "model = CSNN_Model(in_channels=in_channels,num_classes=num_classes).to(device)\n",
    "\n",
    "\n",
    "# weight_path = \"./pretrained_DVS_csnn_128e_91a.t7\"\n",
    "weight_path = \"./pretrained_normal_CIFAR_csnn_150_q.t7\"\n",
    "checkpoint = torch.load(weight_path,map_location=device)\n",
    "model.load_state_dict(checkpoint['net'])\n",
    "\n",
    "#Model evaluation\n",
    "def check_accuracy(loader, model):\n",
    "    if loader.dataset.train:\n",
    "        print(\"Checking on training data\")\n",
    "        \n",
    "    else:\n",
    "        print(\"Checking on testing data\")\n",
    "    \n",
    "    num_correct = 0\n",
    "    num_sample = 0\n",
    "    model.eval()  #(Equivalent to model.train(False)) Nothing learn\n",
    "\n",
    "    with torch.no_grad():   #no need to cal grad\n",
    "        for image,label in loader:\n",
    "            image= image.to(device)\n",
    "            label= label.to(device)\n",
    "            \n",
    "            # T x N x 2312 => N x 2312\n",
    "            out_firing = model(image)\n",
    "\n",
    "            #64x10 output\n",
    "            _ , prediction = out_firing.max(1)  #64x1 (value in 2nd dimension)\n",
    "            num_correct += (prediction==label).sum()\n",
    "            num_sample += prediction.size(0)  #64 (value in 1st dimension)\n",
    "            \n",
    "        print(f'Got {num_correct}/{num_sample} with accuracy {float(num_correct)/float(num_sample)*100:.2f}')\n",
    "        \n",
    "    model.train() #Set back to train mode\n",
    "    return num_correct/num_sample    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = checkpoint['net']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['conv0.weight', 'conv1.weight', 'conv2.weight', 'conv3.weight', 'fc1.weight', 'fc2.weight']\n"
     ]
    }
   ],
   "source": [
    "layer_names = list(a.keys())\n",
    "print(layer_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking on testing data\n",
      "Got 242/264 with accuracy 91.67\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor(0.9167)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "check_accuracy(test_loader,model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'net': OrderedDict([('conv0.weight',\n",
       "               tensor([[[[ 0.1054, -0.0797,  0.1346],\n",
       "                         [-0.1866, -0.0382,  0.0044],\n",
       "                         [ 0.1709, -0.2216, -0.0026]],\n",
       "               \n",
       "                        [[ 0.0033, -0.2210,  0.0303],\n",
       "                         [ 0.0373,  0.0459, -0.2364],\n",
       "                         [ 0.0322,  0.1956, -0.0477]]],\n",
       "               \n",
       "               \n",
       "                       [[[ 0.1043, -0.1445,  0.1487],\n",
       "                         [-0.0976,  0.1981,  0.0043],\n",
       "                         [ 0.2044, -0.2151, -0.0605]],\n",
       "               \n",
       "                        [[ 0.1206,  0.2357, -0.1869],\n",
       "                         [-0.0010, -0.0072,  0.2082],\n",
       "                         [-0.0257,  0.2172,  0.1871]]],\n",
       "               \n",
       "               \n",
       "                       [[[ 0.0471, -0.0992, -0.0632],\n",
       "                         [ 0.0059,  0.1262,  0.1013],\n",
       "                         [ 0.0366,  0.0084,  0.1335]],\n",
       "               \n",
       "                        [[-0.1706, -0.2241, -0.1679],\n",
       "                         [-0.1561,  0.2072, -0.2210],\n",
       "                         [-0.0198, -0.0566, -0.0804]]],\n",
       "               \n",
       "               \n",
       "                       ...,\n",
       "               \n",
       "               \n",
       "                       [[[ 0.1759,  0.1259, -0.2123],\n",
       "                         [-0.1393,  0.0678,  0.0458],\n",
       "                         [ 0.1393,  0.0884,  0.1534]],\n",
       "               \n",
       "                        [[-0.0304, -0.2183,  0.0143],\n",
       "                         [-0.0828,  0.1094,  0.0699],\n",
       "                         [-0.0333,  0.0856, -0.1965]]],\n",
       "               \n",
       "               \n",
       "                       [[[-0.2111,  0.0722,  0.0070],\n",
       "                         [ 0.0548, -0.0760,  0.1014],\n",
       "                         [-0.1288,  0.0707, -0.0336]],\n",
       "               \n",
       "                        [[ 0.0709,  0.0873, -0.1864],\n",
       "                         [ 0.2313,  0.1928,  0.1050],\n",
       "                         [-0.0604,  0.0630, -0.1927]]],\n",
       "               \n",
       "               \n",
       "                       [[[-0.0774, -0.0705,  0.2077],\n",
       "                         [-0.1428,  0.2079,  0.1455],\n",
       "                         [ 0.1286, -0.0764, -0.0474]],\n",
       "               \n",
       "                        [[ 0.0541,  0.2297,  0.1960],\n",
       "                         [-0.0607, -0.0811,  0.2032],\n",
       "                         [-0.1479, -0.1758, -0.2310]]]])),\n",
       "              ('conv1.weight',\n",
       "               tensor([[[[-3.1388e-02,  1.5938e-02, -9.3314e-04],\n",
       "                         [ 6.8523e-03, -2.8146e-02,  1.7871e-02],\n",
       "                         [-1.5363e-02,  1.8734e-02,  4.1272e-02]],\n",
       "               \n",
       "                        [[-1.9721e-02, -1.6584e-02,  4.1417e-02],\n",
       "                         [-1.8607e-02,  1.2380e-02,  4.1548e-03],\n",
       "                         [-2.3886e-02,  4.0154e-02, -6.7581e-03]],\n",
       "               \n",
       "                        [[-3.2853e-03,  3.1882e-02,  1.9597e-02],\n",
       "                         [-3.2635e-02, -2.9644e-02,  8.0347e-03],\n",
       "                         [-8.3122e-03,  2.7842e-02, -7.2841e-04]],\n",
       "               \n",
       "                        ...,\n",
       "               \n",
       "                        [[ 1.5911e-02, -2.8297e-02, -1.8909e-03],\n",
       "                         [-3.2081e-02, -1.0135e-02,  2.4857e-02],\n",
       "                         [-5.3779e-03, -3.1716e-02, -3.0466e-02]],\n",
       "               \n",
       "                        [[-1.4413e-02,  2.1736e-02, -1.4121e-02],\n",
       "                         [-2.6928e-02, -3.1836e-02, -2.3812e-03],\n",
       "                         [-2.0438e-02,  2.6185e-02,  8.7090e-03]],\n",
       "               \n",
       "                        [[-2.1259e-03,  2.5271e-02, -1.7921e-02],\n",
       "                         [-2.1184e-02, -2.4581e-02, -3.4122e-03],\n",
       "                         [ 1.4095e-02, -1.6041e-02, -3.5346e-02]]],\n",
       "               \n",
       "               \n",
       "                       [[[-1.1153e-02,  1.7568e-02,  3.8865e-02],\n",
       "                         [ 4.3342e-02,  9.5803e-03, -3.8701e-02],\n",
       "                         [ 3.9418e-02, -1.7016e-02, -2.6518e-02]],\n",
       "               \n",
       "                        [[ 3.4411e-02,  3.8581e-02,  3.1660e-02],\n",
       "                         [ 2.1911e-02, -1.4920e-03, -4.1784e-03],\n",
       "                         [-1.4349e-03, -3.1027e-02,  2.6758e-02]],\n",
       "               \n",
       "                        [[ 4.3023e-02,  3.6606e-02,  2.5774e-02],\n",
       "                         [ 3.1774e-02,  1.8588e-02, -4.0164e-02],\n",
       "                         [ 3.9518e-04, -1.1200e-02,  6.1969e-04]],\n",
       "               \n",
       "                        ...,\n",
       "               \n",
       "                        [[ 3.7324e-02, -2.2548e-02,  2.3579e-02],\n",
       "                         [-2.8458e-02, -1.2253e-02,  2.0609e-02],\n",
       "                         [ 1.8172e-02,  2.2269e-02,  2.0876e-02]],\n",
       "               \n",
       "                        [[-1.5360e-02,  1.6887e-02,  3.1677e-02],\n",
       "                         [-2.8441e-02,  1.3618e-02,  2.6133e-02],\n",
       "                         [ 2.8842e-02, -8.7173e-03,  4.3617e-03]],\n",
       "               \n",
       "                        [[-1.0189e-02,  2.3571e-02, -3.1194e-02],\n",
       "                         [-2.7629e-02,  3.8261e-02,  3.9851e-02],\n",
       "                         [ 2.4994e-02, -3.8091e-02, -2.3178e-02]]],\n",
       "               \n",
       "               \n",
       "                       [[[-3.0443e-02,  2.0338e-02, -2.5782e-02],\n",
       "                         [ 2.9416e-03,  1.0929e-02, -8.9272e-03],\n",
       "                         [-1.2426e-02, -4.0565e-02, -2.7638e-02]],\n",
       "               \n",
       "                        [[ 6.8487e-03, -1.4681e-02,  1.5815e-02],\n",
       "                         [ 2.8123e-02,  3.0496e-02,  2.3498e-02],\n",
       "                         [-2.6728e-02,  3.2842e-02, -3.6832e-02]],\n",
       "               \n",
       "                        [[-1.8749e-02,  2.6695e-02, -3.6703e-02],\n",
       "                         [ 2.7118e-02, -3.4171e-02, -3.7941e-02],\n",
       "                         [-2.1248e-02,  2.2644e-02,  7.4316e-03]],\n",
       "               \n",
       "                        ...,\n",
       "               \n",
       "                        [[ 2.1063e-02, -4.2285e-02,  1.8008e-02],\n",
       "                         [-9.0596e-03, -3.7242e-02,  1.1674e-02],\n",
       "                         [-3.3708e-02,  2.5210e-02,  3.5222e-02]],\n",
       "               \n",
       "                        [[-2.8673e-02, -1.1301e-02,  2.9480e-02],\n",
       "                         [ 3.6864e-02,  2.9198e-02,  1.0344e-02],\n",
       "                         [ 3.5927e-02,  1.1820e-02,  3.2388e-03]],\n",
       "               \n",
       "                        [[ 5.0710e-03,  3.4931e-02,  1.3257e-02],\n",
       "                         [ 2.0956e-02, -3.6865e-02, -9.6756e-03],\n",
       "                         [ 2.1509e-02,  9.3378e-03,  3.4585e-02]]],\n",
       "               \n",
       "               \n",
       "                       ...,\n",
       "               \n",
       "               \n",
       "                       [[[-3.9355e-02, -6.1418e-03, -2.7033e-02],\n",
       "                         [ 3.5077e-02, -1.3242e-02, -1.6054e-02],\n",
       "                         [ 3.7774e-02, -1.5563e-02, -2.7868e-02]],\n",
       "               \n",
       "                        [[-3.5285e-02,  1.1395e-02,  4.0278e-02],\n",
       "                         [ 3.7454e-04, -4.1057e-02,  2.9149e-02],\n",
       "                         [-2.0821e-02,  2.0425e-04, -4.0913e-02]],\n",
       "               \n",
       "                        [[-3.4626e-02,  3.2751e-02,  3.5294e-02],\n",
       "                         [-2.3747e-02, -2.2084e-02,  3.3568e-02],\n",
       "                         [ 1.6189e-02,  1.7066e-02,  3.6094e-02]],\n",
       "               \n",
       "                        ...,\n",
       "               \n",
       "                        [[ 1.9295e-02, -2.5105e-02,  6.1649e-03],\n",
       "                         [-3.7226e-02,  2.3080e-02,  1.2404e-02],\n",
       "                         [ 7.6599e-03, -1.4293e-02, -3.9146e-02]],\n",
       "               \n",
       "                        [[-2.2621e-02, -9.9456e-05, -1.8180e-02],\n",
       "                         [-5.2825e-03,  1.1496e-03,  1.1824e-02],\n",
       "                         [ 2.6232e-03, -1.8094e-02, -1.3840e-02]],\n",
       "               \n",
       "                        [[-5.0607e-03,  3.1745e-02,  6.7833e-05],\n",
       "                         [-1.3079e-02,  2.6584e-02, -7.7396e-03],\n",
       "                         [-2.5648e-02, -3.3439e-02, -6.1836e-03]]],\n",
       "               \n",
       "               \n",
       "                       [[[ 3.1472e-02,  2.7091e-02, -3.4537e-02],\n",
       "                         [ 1.8646e-02, -4.3828e-02,  1.7765e-02],\n",
       "                         [ 5.5838e-03, -4.0528e-02, -7.1472e-03]],\n",
       "               \n",
       "                        [[ 3.6876e-02, -1.3919e-02,  3.1461e-02],\n",
       "                         [-8.8350e-03,  2.8433e-03,  1.0301e-02],\n",
       "                         [ 3.5808e-02, -1.6714e-02, -4.1657e-02]],\n",
       "               \n",
       "                        [[ 7.7768e-03, -4.0492e-02,  2.6519e-03],\n",
       "                         [ 3.7749e-02,  2.9593e-02, -1.8237e-02],\n",
       "                         [ 2.1309e-03,  1.2144e-02,  2.8553e-04]],\n",
       "               \n",
       "                        ...,\n",
       "               \n",
       "                        [[ 1.2066e-02, -3.7630e-04, -2.1307e-02],\n",
       "                         [-1.1648e-03,  1.2572e-04,  5.4577e-03],\n",
       "                         [-2.9432e-02,  4.0669e-03, -2.7752e-02]],\n",
       "               \n",
       "                        [[-9.5742e-03,  3.5329e-02, -1.9405e-02],\n",
       "                         [-6.6340e-03,  1.5456e-02,  3.4953e-03],\n",
       "                         [-2.0677e-03, -2.5636e-02, -8.1542e-04]],\n",
       "               \n",
       "                        [[ 1.9903e-02, -3.8469e-02, -2.9215e-02],\n",
       "                         [-6.0201e-03,  6.0927e-03,  2.2080e-02],\n",
       "                         [ 1.6599e-02,  2.8636e-02,  2.6515e-02]]],\n",
       "               \n",
       "               \n",
       "                       [[[-3.0798e-02, -1.4853e-02,  3.8210e-02],\n",
       "                         [-2.4291e-02, -3.6625e-02, -2.8322e-02],\n",
       "                         [-2.6948e-02, -3.6441e-03, -3.5375e-02]],\n",
       "               \n",
       "                        [[ 1.4973e-02, -5.2134e-03, -2.6897e-02],\n",
       "                         [ 1.3458e-02, -1.1690e-02,  3.2003e-03],\n",
       "                         [ 2.2652e-02, -6.0944e-03, -8.5792e-03]],\n",
       "               \n",
       "                        [[ 3.4369e-02,  2.2051e-02, -2.5621e-02],\n",
       "                         [ 3.6044e-02, -3.5147e-02,  2.0651e-02],\n",
       "                         [ 3.4419e-02,  1.0794e-02,  3.7472e-02]],\n",
       "               \n",
       "                        ...,\n",
       "               \n",
       "                        [[ 7.2386e-03,  2.0987e-02, -3.5297e-02],\n",
       "                         [ 3.3054e-02, -3.2879e-02, -1.2257e-02],\n",
       "                         [ 2.9871e-02,  2.7029e-02,  1.5877e-02]],\n",
       "               \n",
       "                        [[ 3.6318e-02,  1.8471e-02,  1.0712e-02],\n",
       "                         [-1.9092e-02, -2.6189e-02, -2.0352e-02],\n",
       "                         [-2.0507e-02,  1.4791e-02,  3.4677e-02]],\n",
       "               \n",
       "                        [[ 3.1119e-02, -2.4962e-02,  2.5670e-02],\n",
       "                         [ 1.0338e-02, -2.9010e-02,  2.5528e-03],\n",
       "                         [ 1.1257e-02,  1.2780e-02,  1.3544e-02]]]])),\n",
       "              ('conv2.weight',\n",
       "               tensor([[[[-1.9223e-02,  4.4615e-03, -8.9927e-03],\n",
       "                         [-2.1095e-03, -1.0326e-02,  1.2666e-02],\n",
       "                         [ 1.1264e-02, -2.4685e-02,  2.5956e-02]],\n",
       "               \n",
       "                        [[ 8.4489e-04, -2.3889e-02,  2.8379e-03],\n",
       "                         [-2.0582e-02,  9.7239e-03, -2.0131e-02],\n",
       "                         [ 1.0455e-02, -9.9948e-03,  1.9225e-02]],\n",
       "               \n",
       "                        [[ 2.8925e-02,  5.9604e-03, -2.3746e-03],\n",
       "                         [-1.2417e-02, -2.1251e-02, -1.6719e-02],\n",
       "                         [-2.9168e-02, -1.0187e-02,  8.0399e-03]],\n",
       "               \n",
       "                        ...,\n",
       "               \n",
       "                        [[-2.1781e-02, -2.4720e-02,  2.1204e-02],\n",
       "                         [ 2.5540e-02, -2.8454e-02,  1.9966e-02],\n",
       "                         [ 8.5991e-03,  1.0836e-02, -7.5532e-03]],\n",
       "               \n",
       "                        [[-2.3850e-02,  9.3729e-03,  2.0017e-02],\n",
       "                         [-2.9130e-02, -2.0598e-02,  2.8301e-02],\n",
       "                         [ 5.5682e-03, -1.0354e-03,  2.6805e-02]],\n",
       "               \n",
       "                        [[ 4.4262e-03,  1.0629e-02, -1.0308e-02],\n",
       "                         [-2.6701e-02, -1.4222e-02, -7.2024e-03],\n",
       "                         [ 2.0551e-03,  4.0978e-03,  5.7035e-03]]],\n",
       "               \n",
       "               \n",
       "                       [[[ 1.6122e-02,  1.0663e-02,  3.4889e-04],\n",
       "                         [-1.3028e-02,  3.0029e-02, -4.5531e-03],\n",
       "                         [-1.6658e-03,  1.5664e-02, -1.0844e-02]],\n",
       "               \n",
       "                        [[ 7.2210e-03, -2.2593e-02,  9.0936e-03],\n",
       "                         [-1.4433e-02,  1.5805e-02, -2.2605e-02],\n",
       "                         [ 2.9692e-02,  1.9165e-02, -1.2359e-02]],\n",
       "               \n",
       "                        [[-7.4388e-03, -1.5817e-02,  5.9043e-03],\n",
       "                         [ 1.6165e-02,  2.8467e-03, -2.5761e-02],\n",
       "                         [-2.2512e-03, -1.1740e-02,  2.2013e-02]],\n",
       "               \n",
       "                        ...,\n",
       "               \n",
       "                        [[ 2.3755e-02,  5.6344e-03, -2.3110e-02],\n",
       "                         [-1.9590e-02, -2.9597e-02,  7.3072e-03],\n",
       "                         [ 1.0857e-02,  2.4229e-02, -1.2087e-02]],\n",
       "               \n",
       "                        [[ 2.4922e-02,  1.2945e-02, -2.2661e-02],\n",
       "                         [-2.8914e-02,  7.0881e-04,  1.8099e-02],\n",
       "                         [ 3.7223e-03,  1.6047e-03, -2.2379e-02]],\n",
       "               \n",
       "                        [[ 2.4496e-02,  2.3097e-02, -9.3578e-03],\n",
       "                         [-1.5486e-02,  3.1313e-02,  7.4101e-03],\n",
       "                         [ 2.0951e-02,  2.2054e-02, -2.0068e-02]]],\n",
       "               \n",
       "               \n",
       "                       [[[-2.7565e-03,  2.3413e-02,  9.0657e-03],\n",
       "                         [-3.5273e-04, -3.7122e-03,  6.4703e-03],\n",
       "                         [ 6.0820e-03,  1.1139e-02,  5.2956e-03]],\n",
       "               \n",
       "                        [[ 3.6538e-03,  1.7210e-02, -3.1391e-03],\n",
       "                         [-1.6515e-04, -2.6080e-02,  2.5134e-02],\n",
       "                         [ 1.7942e-02, -3.6365e-04,  2.6398e-02]],\n",
       "               \n",
       "                        [[-1.8222e-02,  1.0924e-02,  2.2015e-02],\n",
       "                         [ 1.6984e-02, -2.5922e-02, -2.7583e-02],\n",
       "                         [-6.2383e-03, -3.1459e-03,  2.8249e-02]],\n",
       "               \n",
       "                        ...,\n",
       "               \n",
       "                        [[-6.0362e-03,  1.5866e-02, -2.9731e-02],\n",
       "                         [ 1.6748e-02, -1.1760e-02, -1.8678e-02],\n",
       "                         [ 2.3849e-02,  2.7616e-02,  1.2153e-02]],\n",
       "               \n",
       "                        [[ 4.4686e-05, -2.6567e-02, -2.3920e-02],\n",
       "                         [ 1.3338e-03,  2.4434e-02,  2.7242e-02],\n",
       "                         [ 2.7301e-02, -1.0907e-02, -5.1325e-03]],\n",
       "               \n",
       "                        [[ 1.9027e-02,  3.2872e-03, -1.6369e-02],\n",
       "                         [-7.4268e-03, -2.3899e-02,  2.7704e-02],\n",
       "                         [-2.8878e-03,  1.6413e-02,  1.4893e-02]]],\n",
       "               \n",
       "               \n",
       "                       ...,\n",
       "               \n",
       "               \n",
       "                       [[[ 2.5261e-02, -5.7708e-03, -1.0447e-02],\n",
       "                         [-1.4264e-02, -1.1818e-02, -1.2371e-02],\n",
       "                         [ 1.5464e-02, -2.3964e-02, -7.1478e-03]],\n",
       "               \n",
       "                        [[-2.3514e-02,  1.1092e-02, -1.1451e-02],\n",
       "                         [ 1.8369e-02, -2.6751e-02, -1.0834e-02],\n",
       "                         [ 1.6577e-02,  1.4557e-02, -2.2513e-02]],\n",
       "               \n",
       "                        [[ 2.8734e-02,  4.9531e-03, -2.2129e-03],\n",
       "                         [-3.1864e-03,  1.8285e-02, -2.2830e-02],\n",
       "                         [ 1.1615e-02,  3.1988e-03, -5.4462e-04]],\n",
       "               \n",
       "                        ...,\n",
       "               \n",
       "                        [[-1.5809e-02,  5.0553e-03,  2.6836e-02],\n",
       "                         [-2.6263e-02, -1.9047e-02, -4.5583e-03],\n",
       "                         [-8.1104e-03,  1.6169e-02, -2.8691e-03]],\n",
       "               \n",
       "                        [[-1.9423e-02, -1.5981e-02,  9.6891e-03],\n",
       "                         [-1.9583e-03,  1.3549e-02,  1.6434e-02],\n",
       "                         [ 9.2433e-03,  2.6028e-02, -2.0818e-02]],\n",
       "               \n",
       "                        [[-1.3624e-02,  6.6197e-03,  5.7369e-03],\n",
       "                         [-1.7111e-02, -2.9464e-02, -1.2617e-02],\n",
       "                         [ 2.0210e-02, -2.9271e-02, -2.0091e-02]]],\n",
       "               \n",
       "               \n",
       "                       [[[-3.1067e-03, -2.4407e-02, -2.2749e-02],\n",
       "                         [ 1.7252e-02,  2.4710e-02, -2.9871e-02],\n",
       "                         [-2.5962e-02, -9.4753e-03,  5.2723e-03]],\n",
       "               \n",
       "                        [[-1.0907e-02, -1.5650e-02,  2.3835e-02],\n",
       "                         [ 8.6421e-03, -7.3798e-03, -2.5478e-02],\n",
       "                         [ 2.1758e-03, -1.4366e-03,  2.3045e-02]],\n",
       "               \n",
       "                        [[-1.0349e-03, -3.3253e-03,  2.6875e-02],\n",
       "                         [ 1.7653e-02, -4.3419e-03,  1.5988e-03],\n",
       "                         [ 1.5302e-02, -5.0602e-03,  1.9963e-03]],\n",
       "               \n",
       "                        ...,\n",
       "               \n",
       "                        [[-3.1629e-03,  6.7651e-04,  7.0236e-03],\n",
       "                         [ 6.3296e-03,  2.4374e-03,  2.4384e-02],\n",
       "                         [ 2.8545e-02,  1.5233e-02,  8.5657e-04]],\n",
       "               \n",
       "                        [[ 1.3497e-02,  1.5964e-02, -2.7665e-02],\n",
       "                         [ 6.0399e-03, -2.3090e-03,  1.5542e-02],\n",
       "                         [-2.1172e-04, -7.1868e-03, -1.4941e-03]],\n",
       "               \n",
       "                        [[ 1.1004e-02, -1.2547e-02,  1.9793e-02],\n",
       "                         [-1.6500e-02,  2.0239e-02, -2.3225e-02],\n",
       "                         [-2.6707e-02, -2.4391e-02,  1.5071e-02]]],\n",
       "               \n",
       "               \n",
       "                       [[[-1.9916e-02, -1.5784e-02,  2.5552e-02],\n",
       "                         [ 2.5541e-02, -1.6165e-02,  9.6664e-03],\n",
       "                         [-2.5632e-02,  2.0541e-02,  1.2149e-03]],\n",
       "               \n",
       "                        [[-5.0549e-03,  1.3205e-02, -1.5550e-02],\n",
       "                         [ 1.7868e-02, -9.2342e-03, -5.4453e-03],\n",
       "                         [-2.9487e-02, -2.8375e-02,  1.6815e-02]],\n",
       "               \n",
       "                        [[-2.0703e-02, -3.2362e-03,  2.6306e-02],\n",
       "                         [-7.7384e-03, -2.4618e-02, -5.5004e-03],\n",
       "                         [ 1.6865e-02, -2.8366e-02, -1.7811e-03]],\n",
       "               \n",
       "                        ...,\n",
       "               \n",
       "                        [[ 1.2398e-02, -3.3202e-03, -3.6366e-03],\n",
       "                         [ 1.0315e-02,  1.2978e-02, -2.4659e-02],\n",
       "                         [ 2.3351e-02, -2.8314e-03, -2.1652e-02]],\n",
       "               \n",
       "                        [[ 2.2488e-03,  9.5031e-03,  1.2882e-02],\n",
       "                         [-5.3895e-03,  9.2776e-03, -1.8878e-02],\n",
       "                         [ 4.5234e-04,  2.3863e-02,  2.4717e-03]],\n",
       "               \n",
       "                        [[ 2.4291e-02, -4.3437e-03,  2.2087e-02],\n",
       "                         [ 1.9284e-02,  2.7497e-02, -2.9599e-03],\n",
       "                         [-1.7358e-03, -2.9961e-03, -2.0194e-02]]]])),\n",
       "              ('conv3.weight',\n",
       "               tensor([[[[-0.0163,  0.0072, -0.0024],\n",
       "                         [-0.0118, -0.0264,  0.0213],\n",
       "                         [ 0.0055, -0.0193, -0.0063]],\n",
       "               \n",
       "                        [[-0.0060,  0.0243, -0.0297],\n",
       "                         [ 0.0092,  0.0133,  0.0120],\n",
       "                         [ 0.0274, -0.0079,  0.0009]],\n",
       "               \n",
       "                        [[-0.0157,  0.0037, -0.0218],\n",
       "                         [ 0.0126, -0.0237,  0.0229],\n",
       "                         [-0.0116,  0.0244,  0.0032]],\n",
       "               \n",
       "                        ...,\n",
       "               \n",
       "                        [[-0.0125, -0.0053,  0.0230],\n",
       "                         [-0.0306, -0.0091, -0.0003],\n",
       "                         [ 0.0264,  0.0116, -0.0192]],\n",
       "               \n",
       "                        [[ 0.0003, -0.0286, -0.0255],\n",
       "                         [ 0.0128,  0.0092,  0.0121],\n",
       "                         [ 0.0266,  0.0151, -0.0221]],\n",
       "               \n",
       "                        [[-0.0173, -0.0186, -0.0305],\n",
       "                         [ 0.0025,  0.0246, -0.0161],\n",
       "                         [-0.0273, -0.0177,  0.0235]]],\n",
       "               \n",
       "               \n",
       "                       [[[-0.0133, -0.0284, -0.0075],\n",
       "                         [-0.0160,  0.0057, -0.0151],\n",
       "                         [ 0.0095, -0.0245, -0.0146]],\n",
       "               \n",
       "                        [[ 0.0053,  0.0185, -0.0285],\n",
       "                         [-0.0182, -0.0222, -0.0067],\n",
       "                         [ 0.0054, -0.0235, -0.0031]],\n",
       "               \n",
       "                        [[-0.0051, -0.0267,  0.0066],\n",
       "                         [-0.0254, -0.0241,  0.0004],\n",
       "                         [ 0.0187, -0.0224, -0.0135]],\n",
       "               \n",
       "                        ...,\n",
       "               \n",
       "                        [[-0.0069,  0.0242,  0.0042],\n",
       "                         [ 0.0137, -0.0130,  0.0143],\n",
       "                         [ 0.0004, -0.0210, -0.0211]],\n",
       "               \n",
       "                        [[ 0.0091,  0.0112, -0.0005],\n",
       "                         [-0.0211,  0.0241,  0.0163],\n",
       "                         [ 0.0146,  0.0184, -0.0012]],\n",
       "               \n",
       "                        [[ 0.0248,  0.0283, -0.0033],\n",
       "                         [ 0.0182,  0.0056,  0.0181],\n",
       "                         [ 0.0085,  0.0042, -0.0089]]],\n",
       "               \n",
       "               \n",
       "                       [[[-0.0111, -0.0301, -0.0092],\n",
       "                         [-0.0220,  0.0249,  0.0228],\n",
       "                         [ 0.0018,  0.0099,  0.0125]],\n",
       "               \n",
       "                        [[ 0.0234, -0.0174, -0.0064],\n",
       "                         [ 0.0099,  0.0235, -0.0119],\n",
       "                         [-0.0050,  0.0034, -0.0170]],\n",
       "               \n",
       "                        [[-0.0164, -0.0124, -0.0102],\n",
       "                         [-0.0054, -0.0129, -0.0162],\n",
       "                         [-0.0229, -0.0281, -0.0176]],\n",
       "               \n",
       "                        ...,\n",
       "               \n",
       "                        [[ 0.0055, -0.0247,  0.0129],\n",
       "                         [-0.0125,  0.0100, -0.0233],\n",
       "                         [ 0.0237, -0.0133, -0.0191]],\n",
       "               \n",
       "                        [[-0.0230,  0.0016, -0.0022],\n",
       "                         [ 0.0116,  0.0094, -0.0010],\n",
       "                         [-0.0156,  0.0160,  0.0136]],\n",
       "               \n",
       "                        [[ 0.0031, -0.0302, -0.0311],\n",
       "                         [ 0.0177, -0.0123, -0.0326],\n",
       "                         [ 0.0053, -0.0320, -0.0015]]],\n",
       "               \n",
       "               \n",
       "                       ...,\n",
       "               \n",
       "               \n",
       "                       [[[-0.0018, -0.0030, -0.0108],\n",
       "                         [-0.0054, -0.0001,  0.0283],\n",
       "                         [ 0.0268,  0.0201,  0.0124]],\n",
       "               \n",
       "                        [[ 0.0083,  0.0021,  0.0229],\n",
       "                         [ 0.0120,  0.0227,  0.0091],\n",
       "                         [-0.0044,  0.0172,  0.0014]],\n",
       "               \n",
       "                        [[ 0.0243,  0.0193,  0.0261],\n",
       "                         [ 0.0158, -0.0274,  0.0001],\n",
       "                         [ 0.0103,  0.0275,  0.0257]],\n",
       "               \n",
       "                        ...,\n",
       "               \n",
       "                        [[ 0.0193, -0.0107, -0.0051],\n",
       "                         [ 0.0223,  0.0172, -0.0170],\n",
       "                         [-0.0132,  0.0060, -0.0041]],\n",
       "               \n",
       "                        [[ 0.0131,  0.0223,  0.0055],\n",
       "                         [-0.0189,  0.0016, -0.0099],\n",
       "                         [-0.0004,  0.0225, -0.0081]],\n",
       "               \n",
       "                        [[ 0.0291,  0.0191,  0.0005],\n",
       "                         [ 0.0251,  0.0121,  0.0093],\n",
       "                         [ 0.0265, -0.0069,  0.0064]]],\n",
       "               \n",
       "               \n",
       "                       [[[-0.0208, -0.0199, -0.0284],\n",
       "                         [-0.0266,  0.0234, -0.0235],\n",
       "                         [-0.0103, -0.0140,  0.0168]],\n",
       "               \n",
       "                        [[-0.0226,  0.0105, -0.0035],\n",
       "                         [ 0.0245, -0.0242, -0.0055],\n",
       "                         [ 0.0228,  0.0152, -0.0088]],\n",
       "               \n",
       "                        [[-0.0277, -0.0136,  0.0053],\n",
       "                         [-0.0264,  0.0108, -0.0217],\n",
       "                         [ 0.0204, -0.0164,  0.0082]],\n",
       "               \n",
       "                        ...,\n",
       "               \n",
       "                        [[ 0.0060,  0.0222,  0.0034],\n",
       "                         [ 0.0160,  0.0114,  0.0111],\n",
       "                         [ 0.0048,  0.0107,  0.0032]],\n",
       "               \n",
       "                        [[-0.0141, -0.0268,  0.0136],\n",
       "                         [-0.0240,  0.0250,  0.0045],\n",
       "                         [ 0.0148, -0.0190,  0.0273]],\n",
       "               \n",
       "                        [[-0.0247,  0.0210, -0.0210],\n",
       "                         [-0.0146, -0.0205,  0.0065],\n",
       "                         [ 0.0108, -0.0188, -0.0013]]],\n",
       "               \n",
       "               \n",
       "                       [[[ 0.0169,  0.0281,  0.0180],\n",
       "                         [-0.0183,  0.0051,  0.0147],\n",
       "                         [ 0.0245,  0.0314,  0.0078]],\n",
       "               \n",
       "                        [[ 0.0165, -0.0011, -0.0195],\n",
       "                         [-0.0290, -0.0238, -0.0005],\n",
       "                         [ 0.0153, -0.0204, -0.0002]],\n",
       "               \n",
       "                        [[ 0.0250,  0.0003, -0.0237],\n",
       "                         [ 0.0037, -0.0173,  0.0178],\n",
       "                         [ 0.0103, -0.0162,  0.0047]],\n",
       "               \n",
       "                        ...,\n",
       "               \n",
       "                        [[ 0.0111, -0.0187,  0.0082],\n",
       "                         [ 0.0176,  0.0058, -0.0250],\n",
       "                         [ 0.0212, -0.0266, -0.0278]],\n",
       "               \n",
       "                        [[-0.0157,  0.0077,  0.0005],\n",
       "                         [ 0.0070, -0.0221,  0.0229],\n",
       "                         [-0.0197,  0.0172, -0.0158]],\n",
       "               \n",
       "                        [[-0.0157, -0.0096,  0.0012],\n",
       "                         [ 0.0144, -0.0156,  0.0074],\n",
       "                         [ 0.0008,  0.0241, -0.0187]]]])),\n",
       "              ('fc1.weight',\n",
       "               tensor([[-0.0097, -0.0047, -0.0076,  ..., -0.0007,  0.0054, -0.0084],\n",
       "                       [-0.0058, -0.0060, -0.0077,  ..., -0.0026, -0.0010, -0.0086],\n",
       "                       [-0.0103, -0.0124,  0.0071,  ..., -0.0123, -0.0126, -0.0124],\n",
       "                       ...,\n",
       "                       [ 0.0110,  0.0144,  0.0113,  ..., -0.0008, -0.0102,  0.0055],\n",
       "                       [-0.0078, -0.0160, -0.0023,  ..., -0.0027, -0.0097,  0.0133],\n",
       "                       [-0.0154, -0.0159, -0.0041,  ...,  0.0123,  0.0127, -0.0019]])),\n",
       "              ('fc2.weight',\n",
       "               tensor([[ 0.0123, -0.0049,  0.0205,  ...,  0.0174,  0.0285,  0.0003],\n",
       "                       [-0.0230, -0.0315,  0.0093,  ..., -0.0155,  0.0042, -0.0039],\n",
       "                       [ 0.0196, -0.0243,  0.0179,  ...,  0.0245, -0.0186,  0.0224],\n",
       "                       ...,\n",
       "                       [-0.0210, -0.0290, -0.0008,  ..., -0.0070,  0.0244,  0.0014],\n",
       "                       [-0.0164, -0.0208,  0.0096,  ...,  0.0094, -0.0101,  0.0061],\n",
       "                       [-0.0013,  0.0094, -0.0307,  ...,  0.0258, -0.0209,  0.0014]]))]),\n",
       " 'TimeWindow': 15,\n",
       " 'epoch': 4,\n",
       " 'acc_record': [0.09800000488758087,\n",
       "  0.09800000488758087,\n",
       "  0.09800000488758087,\n",
       "  0.09800000488758087,\n",
       "  0.09800000488758087]}"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "checkpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "SNN_Research",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
