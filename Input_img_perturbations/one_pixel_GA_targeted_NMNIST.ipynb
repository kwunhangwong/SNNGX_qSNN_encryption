{"cells":[{"cell_type":"code","execution_count":1,"metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["/home/edwin/anaconda3/envs/SNN_env/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n","  from .autonotebook import tqdm as notebook_tqdm\n"]},{"name":"stdout","output_type":"stream","text":["The current layer is: fc1: \n","finished quantized fc1 weights to 8 BITs\n","The current layer is: fc2: \n","finished quantized fc2 weights to 8 BITs\n"]}],"source":["import torch\n","import sys\n","\n","sys.path.append('../quantization_utils')\n","from _Loading_All_Model import *\n","from _Loading_All_Dataloader import * \n","from quantization import *\n","\n","\n","# NMNIST Dataset and pretrained weights\n","batch_size = 1\n","_ , test_loader = choose_dataset(target=\"NMNIST\",batch_size=batch_size,T_BIN=15,dataset_path='../../dataset/')\n","\n","adv_path = \"../pretrained_weights_float32/flipped_8samples-nmnist.t7\"\n","normal_path = \"../pretrained_weights_float32/pre_trained_normal-nmnist_snn_300e.t7\"\n","\n","# Check if a GPU is available and set the device accordingly\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","\n","# Load the encrypted model\n","adv_1 = torch.load(adv_path, map_location=device)\n","adv_model = NMNIST_model(batch_size=batch_size).to(device)\n","adv_model.load_state_dict(adv_1['net'])\n","\n","# Load the normal model\n","norm_2 = torch.load(normal_path, map_location=device)\n","normal_model = NMNIST_model(batch_size=batch_size).to(device)\n","normal_model.load_state_dict(norm_2['net'])\n","quantize_weights_nbits(normal_model,8)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["check_accuracy(test_loader,adv_model)\n","check_accuracy(test_loader,normal_model)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["from Genetic_Algorithm_perturbation import GA_SparseAttack_L0_targeted\n","import matplotlib.pyplot as plt \n","\n","for image,label in test_loader:\n","    image= image.to(device)\n","    label= label.to(device)\n","\n","    if label!=1:\n","        continue\n","\n","    # T x N x 2312 => N x 2312\n","    out_firing = adv_model(image)\n","    #64x10 output\n","    _ , prediction = out_firing.max(1)  #64x1 (value in 2nd dimension)\n","\n","    if (prediction!=label):\n","        continue\n","    print(out_firing.max(1))\n","\n","    target = 6\n","    attack = GA_SparseAttack_L0_targeted(image, label ,target ,adv_model,\n","                 epsil=2000, n_generations=70, population_size=100,      # epsil = L1/Hamming Distance bound\n","                 retain_best=0.4, mutate_chance=0.05)\n","    perturb_img, b,c,d = attack.main()\n","    break\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["from Genetic_Algorithm_perturbation import GA_SparseAttack_L0_targeted_EDGES\n","import matplotlib.pyplot as plt \n","\n","for image,label in test_loader:\n","    image= image.to(device)\n","    label= label.to(device)\n","\n","    if label!=1:\n","        continue\n","\n","    # T x N x 2312 => N x 2312\n","    out_firing = adv_model(image)\n","    #64x10 output\n","    _ , prediction = out_firing.max(1)  #64x1 (value in 2nd dimension)\n","    if (prediction!=label):\n","        continue\n","    print(out_firing.max(1))\n","\n","    target = 7\n","    attack = GA_SparseAttack_L0_targeted_EDGES(image, label ,target ,adv_model,\n","                 epsil=2000, n_generations=70, population_size=100,      # epsil = L1/Hamming Distance bound\n","                 retain_best=0.4, mutate_chance=0.05)\n","    perturb_img, b,c,d = attack.main()\n","    break"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["ploting_raw_img = torch.squeeze(image.to(torch.device('cpu')))\n","ploting_adv_img = torch.squeeze(perturb_img.to(torch.device('cpu')))\n","\n","fig, axs = plt.subplots(1, 10, figsize=(15, 3))\n","\n","# Plotting on each subplot\n","for i, ax in enumerate(axs):\n","    ax.imshow(ploting_adv_img[i][1],cmap='gray')\n","    \n","# Adjust the spacing between subplots\n","plt.tight_layout()\n","\n","# filename = \"./adversarial_1_to_7\"\n","# filepath = filename +\".pdf\"\n","# plt.savefig(filepath,bbox_inches='tight',transparent=True, dpi=300,pad_inches=0.0)\n","\n","\n","fig, axs = plt.subplots(1, 10, figsize=(15, 3))\n","\n","# Plotting on each subplot\n","for i, ax in enumerate(axs):\n","    ax.imshow(ploting_raw_img[i][1],cmap='gray')\n","\n","\n","# Adjust the spacing between subplots\n","plt.tight_layout()\n","\n","# Display the plot\n","plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["out_firing = normal_model(perturb_img.to(device))\n","_ , prediction = out_firing.max(1)  #64x1 (value in 2nd dimension)\n","print(prediction)\n","print(out_firing)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["out_firing = adv_model(perturb_img.to(device))\n","_ , prediction = out_firing.max(1)  #64x1 (value in 2nd dimension)\n","print(prediction)\n","print(out_firing)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["out_firing = normal_model(image.to(device))\n","_ , prediction = out_firing.max(1)  #64x1 (value in 2nd dimension)\n","print(prediction)\n","print(out_firing)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["out_firing = adv_model(image.to(device))\n","_ , prediction = out_firing.max(1)  #64x1 (value in 2nd dimension)\n","print(prediction)\n","print(out_firing)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["delta = perturb_img-image\n","\n","# \n","positve = torch.zeros_like(delta)\n","negative = torch.zeros_like(delta)\n","\n","positve= delta>0\n","negative= delta<0\n","\n","delta = torch.squeeze(delta.to(torch.device('cpu')))\n","positve = torch.squeeze(positve.to(torch.device('cpu')))\n","negative= torch.squeeze(negative.to(torch.device('cpu')))\n","\n","#################################################\n","from matplotlib.colors import LinearSegmentedColormap\n","from matplotlib.colors import ListedColormap\n","\n","cmap1 = ListedColormap(['none', 'red'])\n","cmap2 = ListedColormap(['none','blue'])\n","\n","fig, axs = plt.subplots(1, 10, figsize=(15, 3))\n","\n","# Plotting on each subplot\n","for i, ax in enumerate(axs):\n","\n","    ax.imshow(ploting_adv_img[i][1],cmap='gray')\n","    ax.imshow(positve[i][1],cmap=cmap1)\n","    ax.imshow(negative[i][1],cmap=cmap2)\n","\n","    ax.set_title(f'Subplot {i+1}')\n","\n","\n","# Adjust the spacing between subplots\n","plt.tight_layout()\n","\n","# Display the plot\n","plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["print(ploting_adv_img.shape)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["b"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]}],"metadata":{"kernelspec":{"display_name":"SNN_env","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.16"},"orig_nbformat":4},"nbformat":4,"nbformat_minor":2}
